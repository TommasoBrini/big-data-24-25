{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 102 Spark basics\n",
    "\n",
    "The goal of this lab is to get familiar with Spark programming.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)"
   ]
  },
  {
   "cell_type": "code",
   "id": "11bb4f39692d0432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:58:34.041911Z",
     "start_time": "2024-11-15T15:58:13.131858Z"
    }
   },
   "source": [
    "import org.apache.spark"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://LAPTOP-PSTRJPQO:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1731686301296)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e281923de95ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "// DO NOT EXECUTE - this is needed just to avoid showing errors in the following cells\n",
    "val sc = spark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a0be28e5e823",
   "metadata": {},
   "source": [
    "## 102-1 Spark warm-up\n",
    "\n",
    "Load the ```capra``` and ```divinacommedia``` datasets and try the following actions:\n",
    "- Show their content (```collect```)\n",
    "- Count their rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; what’s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)\n",
    "- Try the ```toDebugString``` function to check the execution plan"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:23:05.085640Z",
     "start_time": "2024-11-15T17:23:04.342970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Load the capra and divinacommedia datasets \n",
    "\n",
    "val rddCapra = sc.textFile(\"../../../../datasets/capra.txt\")\n",
    "val rddDivina = sc.textFile(\"../../../../datasets/divinacommedia.txt\")"
   ],
   "id": "6d2282f6f182c655",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddCapra: org.apache.spark.rdd.RDD[String] = ../../../../datasets/capra.txt MapPartitionsRDD[5] at textFile at <console>:26\r\n",
       "rddDivina: org.apache.spark.rdd.RDD[String] = ../../../../datasets/divinacommedia.txt MapPartitionsRDD[7] at textFile at <console>:27\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:27:55.788722Z",
     "start_time": "2024-11-15T17:27:53.890870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// show their content\n",
    "rddCapra.collect()\n",
    "//rddDivina.collect()"
   ],
   "id": "a5eb42a98219959d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Array[String] = Array(sopra la panca la capra campa, sotto la panca la capra crepa)\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:31:22.088734Z",
     "start_time": "2024-11-15T17:31:21.529753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// count their rows\n",
    "rddCapra.count()"
   ],
   "id": "21c28d110b131a07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: Long = 2\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:34:45.155127Z",
     "start_time": "2024-11-15T17:34:44.444554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// split phrases into word\n",
    "rddCapra.map(x => x.split(\" \")).collect() // crea un array per ogni riga\n",
    "rddCapra.flatMap(x => x.split(\" \")).collect() // collassa tutto in un unico array"
   ],
   "id": "174cf7b2004ad0ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: Array[String] = Array(sopra, la, panca, la, capra, campa, sotto, la, panca, la, capra, crepa)\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:40:22.716326Z",
     "start_time": "2024-11-15T17:40:21.764306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// try toDebugString to check the esecution plan\n",
    "rddCapra.flatMap(x => x.split(\" \")).collect()\n",
    "rddCapra.toDebugString"
   ],
   "id": "eec88e3127940d3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: String =\r\n",
       "(2) ../../../../datasets/capra.txt MapPartitionsRDD[5] at textFile at <console>:26 []\r\n",
       " |  ../../../../datasets/capra.txt HadoopRDD[4] at textFile at <console>:26 []\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "84d04659ace472d8",
   "metadata": {},
   "source": [
    "## 102-2 Basic Spark jobs\n",
    "\n",
    "Implement on Spark the following jobs and test them on both capra and divinacommedia datasets.\n",
    "\n",
    "- **Word count**: count the number of occurrences of each word\n",
    "  - Result: (sopra, 1), (la, 4), …\n",
    "- **Word length count**: count the number of occurrences of words of given lengths\n",
    "  - Result: (2, 4), (5, 8)\n",
    "- Count the average length of words given their first letter (i.e., words that begin with \"s\" have an average length of 5)\n",
    "  - Result: (s, 5), (l, 2), …\n",
    "- Return the inverted index of words (i.e., for each word, list the numbers of lines in which they appear)\n",
    "  - Result: (sopra, (0)), (la, (0, 1)), ...\n",
    "\n",
    "Also, check how sorting works and try to sort key-value RDDs by descending values."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:49:46.552802Z",
     "start_time": "2024-11-15T17:49:45.707970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// WORD COUNT: count the number of occurrences of each word\n",
    "rddCapra.flatMap(x => x.split(\" \"))\n",
    "  .map(x => (x,1))\n",
    "  .reduceByKey((x,y) => x + y)\n",
    "  .collect()"
   ],
   "id": "be62b8f2cde4f87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res24: Array[(String, Int)] = Array((campa,1), (la,4), (panca,2), (sotto,1), (crepa,1), (sopra,1), (capra,2))\r\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T17:55:47.849418Z",
     "start_time": "2024-11-15T17:55:46.992778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// WORD LENGTH COUNT: count the number of occurrences of word of given length\n",
    "rddCapra.flatMap(x => x.split(\" \"))\n",
    "  .map(x => x.length)\n",
    "  .map(x => (x, 1))\n",
    "  .reduceByKey((x,y) => x + y)\n",
    "  .collect()"
   ],
   "id": "dfb8ed892841e046",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res26: Array[(Int, Int)] = Array((2,4), (5,8))\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "1887dce0",
   "metadata": {},
   "source": [
    "## 103-3 Extra Spark jobs\n",
    "\n",
    "Implement the following job.\n",
    "\n",
    "- Co-occurrence count: count the number of co-occurrences in the text. A co-occurrence is defined as \"two distinct words appearing in the same line\".\n",
    "  - In the first line of the *capra* dataset, co-occurrences are:\n",
    "     - (sopra, la), (sopra, panca), (sopra, capra), (sopra, campa)\n",
    "     - (la, sopra), (la, panca), (la, capra), (la, campa) \n",
    "     - (panca, sopra), (panca, la), (panca, capra), (panca, campa)\n",
    "     - (capra, sopra), (capra, la), (capra, panca), (capra, campa)\n",
    "     - (campa, sopra), (campa, la), (campa, panca), (campa, capra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
